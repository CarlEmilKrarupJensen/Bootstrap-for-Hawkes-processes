{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e19fd5b",
   "metadata": {},
   "source": [
    "### ***Bootstrap parameter estimation for hawkes processes with exponential kernel***\n",
    "In this notebook functions as an empirical test of the framework described in the paper \"Bootstrap inference for Hawkes processes\"\n",
    "The functions below simulate hawkes processes with exponential kernel and true parameters. Hereafter a variety of bootstrap schemes are implemented for estimating coverage probabilities of these parameters. Respectively the fixed intensity bootstrap and recursive intensity bootstrap are implemented and hereafter nonparametric versions of these are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33819d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import chi2, norm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import chi2\n",
    "np.set_printoptions(precision=6, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "848b8101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b624e811fd184e9a88a6a7db8897e52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='μ', max=1.0), FloatSlider(value=0.8, description='α'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_hawkes_interactive_scaled(mu=0.5, alpha=0.8, beta=1.5, T=100, M=1.0, k=10.0)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_hawkes(mu, alpha, beta, T, M, k):\n",
    "    \"\"\"\n",
    "    Simulate a single realization of a Hawkes process with exponential kernel using Ogata's thinning algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mu : float\n",
    "        Baseline intensity.\n",
    "    alpha : float\n",
    "        Jump size for each event.\n",
    "    beta : float\n",
    "        Decay rate of the exponential kernel.\n",
    "    T : float\n",
    "        End time for simulation (after burn-in).\n",
    "    M : float\n",
    "        Upper bound for the intensity (thinning envelope).\n",
    "    k : float\n",
    "        Length of the burn-in period. We simulate over [-k, T] and discard times <= 0.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    events : list of float\n",
    "        Event times in (0, T] (post burn-in).\n",
    "    \"\"\"\n",
    "    all_events = []\n",
    "    t = -k  # We define the burn-in period as [-k, 0] and start the simulation here\n",
    "    # Ogata's thinning algorithm\n",
    "    while True:\n",
    "        # generate candidate time\n",
    "        u = np.random.exponential(scale=1.0 / M)\n",
    "        t += u\n",
    "        if t > T:\n",
    "            break\n",
    "\n",
    "        # compute conditional intensity at time t\n",
    "        intensity = mu + sum(alpha * np.exp(-beta * (t - ti)) for ti in all_events)\n",
    "\n",
    "        # thinning step\n",
    "        if np.random.uniform() <= intensity / M:\n",
    "            all_events.append(t)\n",
    "            \n",
    "    # discard burn-in events\n",
    "        events = [ti for ti in all_events if ti > 0]\n",
    "    return events \n",
    "\n",
    "def intensity_on_grid(mu, alpha, beta, events, T, n_points=500):\n",
    "    t_grid = np.linspace(0, T, n_points)\n",
    "    lam = np.array([mu + sum(alpha * beta * np.exp(-beta * (t - ti))\n",
    "                              for ti in events if ti < t)\n",
    "                    for t in t_grid])\n",
    "    return t_grid, lam\n",
    "\n",
    "def plot_hawkes_interactive_scaled(mu=0.5, alpha=0.8, beta=1.5,\n",
    "                                   T=100, M=1.0, k=10.0):\n",
    "    events = simulate_hawkes(mu, alpha, beta, T, M, k)\n",
    "    t_grid, lam = intensity_on_grid(mu, alpha, beta, events, T)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "    ax1.step(events, np.arange(1, len(events)+1),\n",
    "             where='post', label='Cumulative Events', color = 'blue')\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Cumulative Events')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.5, color = 'black')\n",
    "    ax1.set_xlim(0, T)\n",
    "    ax1.set_ylim(0, len(events) + 1)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(t_grid, lam, '-', label='Intensity λ(t)', color='red', alpha=0.5)\n",
    "    ax2.set_ylim(lam.min(), lam.max() * 1.1)\n",
    "    ax2.set_ylabel('Intensity λ(t)')\n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2,\n",
    "               loc='upper left', fontsize='small')\n",
    "\n",
    "    plt.title(f'Hawkes Process (μ={mu}, α={alpha}, β={beta})')\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    plot_hawkes_interactive_scaled,\n",
    "    mu=FloatSlider(min=0.0, max=1.0, step=0.1, value=0.5, description='μ'),\n",
    "    alpha=FloatSlider(min=0.0, max=2.0, step=0.1, value=0.8, description='α'),\n",
    "    beta=FloatSlider(min=0.1, max=5.0, step=0.1, value=1.5, description='β'),\n",
    "    T=IntSlider(min=10, max=200, step=10, value=100, description='T'),\n",
    "    M=FloatSlider(min=0.5, max=100.0, step=0.1, value=1.0, description='M'),\n",
    "    k=FloatSlider(min=0.0, max=50.0, step=1.0, value=10.0, description='k'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01353f98",
   "metadata": {},
   "source": [
    "We now define the helper functions for the bootstrap schemes and the monte carlo simulation to generate confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "484194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_replicates(N, mu, alpha, beta, T, M, k, seed=None):\n",
    "    \"\"\"\n",
    "    Generate N Monte Carlo replicates of a Hawkes process.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Number of replicates.\n",
    "    mu, alpha, beta, T, M, k : as in simulate_hawkes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    replicates : list of lists\n",
    "        A list with N elements, each being the list of post burn-in event times.\n",
    "    \"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    # generate N replicates of the Hawkes process using the simulate_hawkes function\n",
    "    replicates = []\n",
    "    for _ in range(N):\n",
    "        events = simulate_hawkes(mu, alpha, beta, T, M, k)\n",
    "        replicates.append(events)\n",
    "    return replicates\n",
    "\n",
    "# We define re reparameterized log-likelihood function for the Hawkes process\n",
    "def hawkes_loglik(params, events, T):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood of a Hawkes process with exponential kernel.\n",
    "    \n",
    "    params: array-like [mu, alpha, beta]\n",
    "    events: list/array of event times in (0, T]\n",
    "    T: float, observation window end\n",
    "    \"\"\"\n",
    "    mu, eta, beta = params\n",
    "    # enforce on parameters for stability\n",
    "    if mu <= 0 or eta < 0 or eta >= 1 or beta <= 0:\n",
    "        return np.inf\n",
    "    \n",
    "    n = len(events)\n",
    "    log_term = 0.0\n",
    "    for i, ti in enumerate(events):\n",
    "        # intensity at ti\n",
    "        decay_sum = 0.0\n",
    "        for tj in events[:i]:\n",
    "            decay_sum += eta * beta * np.exp(-beta * (ti - tj))\n",
    "        lam = mu + decay_sum\n",
    "        if lam <= 0:\n",
    "            return np.inf\n",
    "        log_term += np.log(lam)\n",
    "    \n",
    "    # compensator: mu*T + eta * sum_j (1 - exp(-beta*(T - t_j)))\n",
    "    compensator = mu * T + eta * np.sum(1 - np.exp(-beta * (T - np.array(events))))\n",
    "    # we return the negative log-likelihood for minimization later\n",
    "    return -(log_term - compensator)\n",
    "\n",
    "def ell_T(events, theta, T):\n",
    "    \"\"\"\n",
    "    The true log-likelihood of the Hawkes data\n",
    "    \"\"\"\n",
    "    return -hawkes_loglik(theta, events, T)\n",
    "\n",
    "def fit_hawkes_MLE(events, T, init_params=None):\n",
    "    \"\"\"\n",
    "    Fit Hawkes MLE via Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS-B) method, and returns MLE params.\n",
    "    \"\"\"\n",
    "    if init_params is None:\n",
    "        init_params = np.array([len(events)/T, 0.5, 1.0])  # mu, eta, beta\n",
    "    bounds = [(1e-6, None), (0, 1-1e-6), (1e-6, None)]\n",
    "    res = minimize(hawkes_loglik, init_params, args=(events, T),\n",
    "                   method='L-BFGS-B', bounds=bounds)\n",
    "    return res.x\n",
    "\n",
    "def Lambda(t, events, params):\n",
    "    \"\"\"\n",
    "    Integrated intensity for Hawkes with exp kernel up to time t.\n",
    "    \"\"\"\n",
    "    mu, alpha, beta = params\n",
    "    # baseline part\n",
    "    val = mu * t\n",
    "    # kernel part: for each event tj < t, add alpha*(1 - exp(-beta*(t - tj)))\n",
    "    ev = np.array(events)\n",
    "    mask = ev < t\n",
    "    val += alpha * np.sum(1 - np.exp(-beta * (t - ev[mask])))\n",
    "    return val\n",
    "\n",
    "\n",
    "def Lambda_inv(s, events, params, T, tol=1e-5, max_iter=50):\n",
    "    \"\"\"\n",
    "    Invert the integrated intensity function for Hawkes with exponential kernel using newton-raphson.\n",
    "    \n",
    "    Solves Lambda(t) - s = 0 with starting guess t0 = (s / Lambda(T)) * T.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s : float\n",
    "        Target integrated intensity.\n",
    "    events : list of floats\n",
    "        Observed event times (for the fixed intensity).\n",
    "    params : array-like [mu, alpha, beta]\n",
    "        Hawkes parameters.\n",
    "    T : float\n",
    "        Upper bound for t.\n",
    "    tol : float\n",
    "        Convergence tolerance on |Lambda(t) - s|.\n",
    "    max_iter : int\n",
    "        Maximum number of Newton steps.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t : float\n",
    "        Approximate solution of Λ(t) = s.\n",
    "    \"\"\"\n",
    "    # Precompute the integrated intensity and check range\n",
    "    s_max = Lambda(T, events, params)\n",
    "    if not (0 <= s <= s_max):\n",
    "        raise ValueError(f\"s={s} out of [0, Λ(T)={s_max}]\")\n",
    "\n",
    "    # 1) Try Newton–Raphson\n",
    "    try:\n",
    "        # initial guess\n",
    "        t = (s / s_max) * T\n",
    "        mu, eta, beta = params\n",
    "        for _ in range(max_iter):\n",
    "            # compute Λ(t) and λ(t)\n",
    "            ev = np.array(events)\n",
    "            mask = ev < t\n",
    "            # Λ(t)\n",
    "            L_t = mu*t + eta * np.sum(1 - np.exp(-beta*(t - ev[mask])))\n",
    "            # λ(t)\n",
    "            lam_t = mu + eta*beta * np.sum(np.exp(-beta*(t - ev[mask])))\n",
    "            # Newton step\n",
    "            diff = L_t - s\n",
    "            if abs(diff) < tol:\n",
    "                return t\n",
    "            t -= diff/lam_t\n",
    "            t = max(min(t, T), 0.0)\n",
    "        # In case newton fails to converge we try bisection\n",
    "        raise RuntimeError(\"Newton failed\")\n",
    "    except Exception:\n",
    "        # 2) Bisection method\n",
    "        low, high = 0.0, T\n",
    "        while high - low > tol:\n",
    "            mid = 0.5*(low + high)\n",
    "            if Lambda(mid, events, params) < s:\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        return 0.5*(low + high)\n",
    "\n",
    "\n",
    "#  Compute and rescale transformed waiting times v_i^c for non parametric bootstrap.\n",
    "def compute_rescaled_residuals(events, T, theta):\n",
    "    \"\"\"\n",
    "    Compute rescaled waiting times residuals.\n",
    "    Returns v_c so that sum(v_c)=n (or n+1 if you include the final interval).\n",
    "    \"\"\"\n",
    "    mu, eta, beta = theta\n",
    "\n",
    "    # Since we use alpha in the integrated intensity, we need to compute it from eta and beta.\n",
    "    alpha = eta * beta\n",
    "\n",
    "    # 1) compute the s_i = Λ(t_i) − Λ(t_{i−1})\n",
    "    s_vals = []\n",
    "    prev = 0.0\n",
    "    for ti in events:\n",
    "        s_vals.append(Lambda(ti, events, (mu, alpha, beta))\n",
    "                      - Lambda(prev, events, (mu, alpha, beta)))\n",
    "        prev = ti\n",
    "\n",
    "    # 3) normalize so that sum(v_c) = n\n",
    "    s = np.array(s_vals)\n",
    "    n = len(s)\n",
    "    total = s.sum()            \n",
    "    v_c = s * n / total\n",
    "    return v_c\n",
    "\n",
    "\n",
    "def compute_finite_diff_hessian(loglik_func, theta_hat, events, T, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Approximate the Hessian matrix of loglik_func at theta_hat via central finite differences.\n",
    "    Here we differ from the function in the paper make computation more efficient. The result is numerically the same.\n",
    "    \"\"\"\n",
    "    p = len(theta_hat)\n",
    "    H = np.zeros((p, p))\n",
    "    base = loglik_func(theta_hat, events, T)\n",
    "    # step size: eps * (1 + |theta|)\n",
    "    #h = eps * (1 + np.abs(theta_hat))\n",
    "    h = np.cbrt(eps) * (1+np.maximum(np.abs(theta_hat), 1.0))\n",
    "    for i in range(p):\n",
    "        for j in range(i, p):\n",
    "            theta_ip = theta_hat.copy()\n",
    "            theta_im = theta_hat.copy()\n",
    "            theta_jp = theta_hat.copy()\n",
    "            theta_jm = theta_hat.copy()\n",
    "            \n",
    "            theta_ip[i] += h[i]\n",
    "            theta_im[i] -= h[i]\n",
    "            theta_jp[j] += h[j]\n",
    "            theta_jm[j] -= h[j]\n",
    "            \n",
    "            f_pp = loglik_func(theta_ip, events, T)\n",
    "            f_pm = loglik_func(np.array([theta_ip[k] if k!=j else theta_ip[k]-h[j] for k in range(p)]), events, T)\n",
    "            f_mp = loglik_func(np.array([theta_im[k] if k!=j else theta_im[k]+h[j] for k in range(p)]), events, T)\n",
    "            f_mm = loglik_func(theta_im, events, T)\n",
    "            \n",
    "            H_ij = (f_pp - f_pm - f_mp + f_mm) / (4 * h[i] * h[j])\n",
    "            H[i, j] = H_ij\n",
    "            H[j, i] = H_ij\n",
    "    return H\n",
    "\n",
    "\n",
    "def asymptotic_inference(events, T, theta0, alpha=0.05, eps=1e-4):\n",
    "    \"\"\"\n",
    "    Asymptotic CIs and LRT, with alpha-CI and stationarity/Hessian flags.\n",
    "    \"\"\"\n",
    "    # 1) MLE\n",
    "    theta_hat = fit_hawkes_MLE(events, T)\n",
    "    mu_h, eta_h, beta_h = theta_hat\n",
    "    \n",
    "    # 2) Hessian of neg log-lik\n",
    "    H_nll = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T, eps=eps)\n",
    "    cov_hat = np.linalg.inv(H_nll)\n",
    "    \n",
    "    # 3) Marginal CIs for (mu, eta, beta)\n",
    "    z = norm.ppf(1 - alpha/2)\n",
    "    se = np.sqrt(np.diag(cov_hat))\n",
    "    ci_lower = theta_hat - z*se\n",
    "    ci_upper = theta_hat + z*se\n",
    "    \n",
    "    # 4) Delta-method CI for alpha = eta*beta\n",
    "    grad_alpha = np.array([0.0, beta_h, eta_h])\n",
    "    var_alpha = grad_alpha @ cov_hat @ grad_alpha\n",
    "    alpha_hat = eta_h * beta_h\n",
    "    ci_alpha = (alpha_hat - z*np.sqrt(var_alpha),\n",
    "                alpha_hat + z*np.sqrt(var_alpha))\n",
    "    \n",
    "    # 5) LRT\n",
    "    ll_hat = ell_T(events, theta_hat, T)\n",
    "    ll_0   = ell_T(events, theta0, T)\n",
    "    LR_obs = 2*(ll_hat - ll_0)\n",
    "    pval = 1 - chi2.cdf(LR_obs, df=len(theta0))\n",
    "    LR_reject = int(pval < alpha)\n",
    "    \n",
    "    # 6) stationarity and Hessian checks\n",
    "\n",
    "    # -- stationarity\n",
    "    stationarity_fail = (eta_h >= 1)\n",
    "\n",
    "    # -- Hessian (observed information) definiteness\n",
    "    #    1) symmetrize and regularize\n",
    "    H_sym = 0.5*(H_nll + H_nll.T)\n",
    "    H_reg = H_sym + 1e-4*np.eye(H_sym.shape[0])\n",
    "\n",
    "    #    2) try eigenvalues first\n",
    "    try:\n",
    "        eigs = np.linalg.eigvalsh(H_reg)\n",
    "        hessian_fail = np.any(eigs <= 0)\n",
    "    except np.linalg.LinAlgError:\n",
    "        #    3) fallback: Cholesky test\n",
    "        try:\n",
    "            np.linalg.cholesky(H_reg)\n",
    "            hessian_fail = False\n",
    "        except np.linalg.LinAlgError:\n",
    "            hessian_fail = True\n",
    "    \n",
    "    return {\n",
    "        'theta_hat': theta_hat,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'ci_alpha': ci_alpha,\n",
    "        'coverage': ((theta0 >= ci_lower) & (theta0 <= ci_upper)).astype(int),\n",
    "        'coverage_alpha': int(theta0[1]*theta0[2] >= ci_alpha[0] and theta0[1]*theta0[2] <= ci_alpha[1]),\n",
    "        'LR_obs': LR_obs,\n",
    "        'LR_reject': LR_reject,\n",
    "        'stationarity_fail': stationarity_fail,\n",
    "        'hessian_fail': hessian_fail\n",
    "    }\n",
    "\n",
    "## Helper functions\n",
    "def _draw_bootstrap_sample(events, theta_hat, T, s_max, invert_lambda):\n",
    "    \"\"\"Generate one bootstrap sample of event times via given inversion.\"\"\"\n",
    "    cum, s_vals = 0.0, []\n",
    "    while True:\n",
    "        v = np.random.exponential() # sample from the exponential distribution with parameter 1\n",
    "        if cum + v > s_max: # check if the next event exceeds the integrated intensity evaluated at T\n",
    "            break\n",
    "        cum += v; s_vals.append(cum) # store the jump times\n",
    "    return [invert_lambda(s, events, theta_hat, T) for s in s_vals] # maps back to original event times\n",
    "\n",
    "def _compute_studentized_t(boot_est, boot_hess, theta_hat, events, T):\n",
    "    \"\"\"\n",
    "    Return (B x p) t-stats and original SEs, using the true 'events'\n",
    "    to recompute the original Hessian.\n",
    "    \"\"\"\n",
    "    p = len(theta_hat)\n",
    "    B = boot_est.shape[0]\n",
    "    # compute original Hessian from events\n",
    "    H_orig = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T, eps=1e-4)\n",
    "    cov_orig = np.linalg.inv(H_orig)\n",
    "    # guard against negative variances\n",
    "    var_orig = np.diag(cov_orig) / T\n",
    "    var_orig[var_orig <= 0] = np.nan\n",
    "    se_orig = np.sqrt(var_orig)\n",
    "\n",
    "    t_stats = np.full((B, p), np.nan)\n",
    "    for b in range(B):\n",
    "        cov_b = np.linalg.inv(boot_hess[b])\n",
    "        var_b = np.diag(cov_b) / T\n",
    "        var_b[var_b <= 0] = np.nan\n",
    "        se_b = np.sqrt(var_b)\n",
    "        valid = ~np.isnan(se_b)\n",
    "        t_stats[b, valid] = (boot_est[b, valid] - theta_hat[valid]) / se_b[valid]\n",
    "    return t_stats, se_orig\n",
    "\n",
    "def _symmetrized_ci(theta_hat, t_stats, se_orig, alpha_ci):\n",
    "    \"\"\"Compute symmetrized-t CI for each parameter.\"\"\"\n",
    "    p = len(theta_hat)\n",
    "    ci_low = np.zeros(p); ci_up = np.zeros(p)\n",
    "    ## coumpute confidence intervals for each parameter with 1-alpha_ci confidence level\n",
    "    for j in range(p):\n",
    "        tj = t_stats[:, j]; tj = tj[np.isfinite(tj)]\n",
    "        if len(tj) == 0:\n",
    "            ci_low[j] = ci_up[j] = np.nan # if t stats are all NaN, set CI to NaN\n",
    "        else: # compute the CI\n",
    "            med = np.median(tj)\n",
    "            pool = np.abs(np.concatenate([tj, 2*med - tj]))\n",
    "            q = np.quantile(pool, 1 - alpha_ci)\n",
    "            ci_low[j] = theta_hat[j] - q * se_orig[j]\n",
    "            ci_up[j]  = theta_hat[j] + q * se_orig[j]\n",
    "    return ci_low, ci_up\n",
    "\n",
    "def _studentized_alpha_ci(theta_hat, boot_est, boot_hess, se_orig_alpha, alpha_ci, T):\n",
    "    \"\"\"Compute studentized symmetrized CI for alpha = eta*beta.\"\"\"\n",
    "    alpha_hat = theta_hat[1]*theta_hat[2]\n",
    "    B = boot_est.shape[0]\n",
    "    t_alpha = np.full(B, np.nan)\n",
    "    # compute t-stats for alpha for each bootstrap sample\n",
    "    for b in range(B):\n",
    "        eta_b, beta_b = boot_est[b,1], boot_est[b,2]\n",
    "        grad_b = np.array([0.0, beta_b, eta_b])\n",
    "        Sigma_b = np.linalg.inv(boot_hess[b])\n",
    "        var_b = grad_b @ Sigma_b @ grad_b\n",
    "        se_b  = np.sqrt(var_b / T) if var_b > 0 else np.nan\n",
    "        if se_b > 0:\n",
    "            t_alpha[b] = (eta_b*beta_b - alpha_hat) / se_b\n",
    "    t_alpha = t_alpha[np.isfinite(t_alpha)]\n",
    "    if len(t_alpha)==0:\n",
    "        return (np.nan, np.nan)\n",
    "    # Center and symmetrize confidence intervals\n",
    "    med = np.median(t_alpha)\n",
    "    pool = np.abs(np.concatenate([t_alpha, 2*med - t_alpha]))\n",
    "    q = np.quantile(pool, 1 - alpha_ci)\n",
    "    return (alpha_hat - q * se_orig_alpha, alpha_hat + q * se_orig_alpha)\n",
    "\n",
    "\n",
    "def fixed_intensity_bootstrap(events, T, B, true_params, alpha_ci=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    Fixed-Intensity Bootstrap (FIB) with symmetrized-t CI \n",
    "    and percentile fallback on Hessian failure.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    theta_hat = fit_hawkes_MLE(events, T)\n",
    "    mu_h, eta_h, beta_h = theta_hat\n",
    "\n",
    "    # 1) sanity checks\n",
    "    stationarity_fail = (eta_h >= 1)\n",
    "    #H_nll            = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T)\n",
    "    #hessian_fail     = np.any(np.linalg.eigvalsh(H_nll) <= 0)\n",
    "    \n",
    "\n",
    "    H_nll = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T)\n",
    "    # symmetrize + tiny ridge\n",
    "    H_sym = 0.5*(H_nll + H_nll.T)\n",
    "    H_reg = H_sym + 1e-6*np.eye(H_sym.shape[0])\n",
    "    try:\n",
    "        eigs = np.linalg.eigvalsh(H_reg)\n",
    "        hessian_fail = np.any(eigs <= 0)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fallback to Cholesky\n",
    "        try:\n",
    "            np.linalg.cholesky(H_reg)\n",
    "            hessian_fail = False\n",
    "        except np.linalg.LinAlgError:\n",
    "            hessian_fail = True\n",
    "\n",
    "\n",
    "    # 2) observed LR\n",
    "    ll_hat, ll_0 = ell_T(events, theta_hat, T), ell_T(events, true_params, T)\n",
    "    LR_obs       = 2 * (ll_hat - ll_0)\n",
    "\n",
    "    # 3) bootstrap draws\n",
    "    s_max       = Lambda(T, events, theta_hat) # fixing the intensity\n",
    "    boot_est    = []\n",
    "    LR_star     = []\n",
    "    boot_hess = []   \n",
    "    for _ in range(B):\n",
    "        t_star = _draw_bootstrap_sample(events, theta_hat, T, s_max, Lambda_inv)\n",
    "        th_b    = fit_hawkes_MLE(t_star, T)\n",
    "        boot_est.append(th_b) # store the bootstrap estimates\n",
    "        LR_star.append(2*(ell_T(t_star, th_b, T)\n",
    "                          - ell_T(t_star, theta_hat, T))) #store the bootstrap Likelihood ratio\n",
    "        H_B = compute_finite_diff_hessian(hawkes_loglik, th_b, t_star, T)\n",
    "        boot_hess.append(H_B) #store the bootstrap Hessian\n",
    "\n",
    "    boot_est   = np.vstack(boot_est) #stack the bootstrap estimates\n",
    "    alpha_boot = boot_est[:,1] * boot_est[:,2] #estimate alpha for each bootstrap sample\n",
    "\n",
    "    # 4) build CIs in case of Hessian failure\n",
    "    if hessian_fail:\n",
    "        # -- percentile fallback --\n",
    "        ci_low   = np.percentile(boot_est,   100*(alpha_ci/2),    axis=0)\n",
    "        ci_up    = np.percentile(boot_est,   100*(1-alpha_ci/2),  axis=0)\n",
    "        ci_alpha = np.percentile(alpha_boot, [100*(alpha_ci/2),\n",
    "                                             100*(1-alpha_ci/2)])\n",
    "        t_stats  = None\n",
    "\n",
    "    else:\n",
    "        # -- studentized‐t block --\n",
    "        #cov_orig      = np.linalg.inv(H_nll) # compute the covariance matrix (asymptotic covariance)\n",
    "        try:\n",
    "            cov_orig = np.linalg.inv(H_reg)\n",
    "        except np.linalg.LinAlgError:\n",
    "            cov_orig = np.linalg.pinv(H_reg)\n",
    "\n",
    "\n",
    "\n",
    "        with np.errstate(invalid=\"ignore\"):\n",
    "            se_orig   = np.sqrt(np.diag(cov_orig) / T) \n",
    "        #Compute the t-stats for each bootstrap sample and confidence interval\n",
    "        t_stats, _    = _compute_studentized_t(boot_est, boot_hess,\n",
    "                                               theta_hat, events, T) \n",
    "        ci_low, ci_up = _symmetrized_ci(theta_hat, t_stats, se_orig, alpha_ci)\n",
    "\n",
    "        # α = η·β studentized‐t\n",
    "        grad0       = np.array([0.0, beta_h, eta_h])\n",
    "        var0_alpha  = max(grad0 @ cov_orig @ grad0, 0.0)\n",
    "        se0_alpha   = np.sqrt(var0_alpha / T)\n",
    "        ci_alpha    = _studentized_alpha_ci(theta_hat, boot_est, boot_hess,\n",
    "                                            se0_alpha, alpha_ci, T)\n",
    "\n",
    "    # 5) coverage flags & return\n",
    "    #check if the true parameters are in the confidence intervals\n",
    "    coverage       = ((true_params >= ci_low) & (true_params <= ci_up)).astype(int) \n",
    "    alpha0         = true_params[1] * true_params[2]\n",
    "    coverage_alpha = int(ci_alpha[0] <= alpha0 <= ci_alpha[1])\n",
    "    boot_lr_rej    = int(np.mean(np.array(LR_star) >= LR_obs) < alpha_ci) # Likelihood ratio test rejection\n",
    "\n",
    "    return {\n",
    "        'theta_hat':        theta_hat,\n",
    "        'ci_lower':         ci_low,\n",
    "        'ci_upper':         ci_up,\n",
    "        'ci_alpha':         ci_alpha,\n",
    "        't_stats':          t_stats,\n",
    "        'coverage':         coverage,\n",
    "        'coverage_alpha':   coverage_alpha,\n",
    "        'boot_lr_reject':   boot_lr_rej,\n",
    "        'stationarity_fail':stationarity_fail,\n",
    "        'hessian_fail':     hessian_fail\n",
    "    }\n",
    "\n",
    "\n",
    "def recursive_intensity_bootstrap(events, T, B, true_params, alpha_ci=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    Recursive-Intensity Bootstrap (RIB) with symmetrized-t CI \n",
    "    and percentile fallback on Hessian failure.\n",
    "    \"\"\"\n",
    "    ### Follows the same structure as fixed_intensity_bootstrap ###\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # 1) Fit original MLE\n",
    "    theta_hat = fit_hawkes_MLE(events, T)\n",
    "    mu_h, eta_h, beta_h = theta_hat\n",
    "\n",
    "    # 2) Sanity checks\n",
    "\n",
    "    stationarity_fail = (eta_h >= 1)\n",
    "    H_orig = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T)\n",
    "\n",
    "    # robust PD test\n",
    "    H_sym = 0.5 * (H_orig + H_orig.T)\n",
    "    H_reg = H_sym + 1e-8 * np.eye(H_sym.shape[0])\n",
    "    try:\n",
    "        eigs = np.linalg.eigvalsh(H_reg)\n",
    "        hessian_fail = np.any(eigs <= 0)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fallback to Cholesky\n",
    "        try:\n",
    "            np.linalg.cholesky(H_reg)\n",
    "            hessian_fail = False\n",
    "        except np.linalg.LinAlgError:\n",
    "            hessian_fail = True\n",
    "\n",
    "\n",
    "    # 3) Observed LRT statistic\n",
    "    ll_hat, ll_0 = ell_T(events, theta_hat, T), ell_T(events, true_params, T)\n",
    "    LR_obs       = 2 * (ll_hat - ll_0)\n",
    "\n",
    "    # 4) Generate B bootstrap samples\n",
    "    s_max = mu_h * T\n",
    "    boot_est = []\n",
    "    LR_star  = []\n",
    "    boot_hess = []\n",
    "    for _ in range(B):\n",
    "        cum, t_star = 0.0, []\n",
    "        while True:\n",
    "            v = np.random.exponential() # sample from the exponential distribution with parameter 1\n",
    "            if cum + v > s_max:\n",
    "                break\n",
    "            cum += v\n",
    "            t_star.append(Lambda_inv(cum, t_star, theta_hat, T)) # maps back to original event times using the bootstrap sample\n",
    "\n",
    "        th_b = fit_hawkes_MLE(t_star, T)\n",
    "        boot_est.append(th_b)\n",
    "        LR_star.append(2*(ell_T(t_star, th_b, T)\n",
    "                          - ell_T(t_star, theta_hat, T)))\n",
    "        H_B = compute_finite_diff_hessian(hawkes_loglik, th_b, t_star, T)\n",
    "        boot_hess.append(H_B) # store the bootstrap Hessian\n",
    "\n",
    "    boot_est  = np.vstack(boot_est) # stack the bootstrap estimates\n",
    "    alpha_boot = boot_est[:,1] * boot_est[:,2]\n",
    "\n",
    "    # 5) CI construction with fallback\n",
    "    if hessian_fail:\n",
    "        # percentile CIs\n",
    "        ci_low   = np.percentile(boot_est,     100*(alpha_ci/2), axis=0)\n",
    "        ci_up    = np.percentile(boot_est,     100*(1-alpha_ci/2), axis=0)\n",
    "        ci_alpha = np.percentile(alpha_boot,   [100*(alpha_ci/2),\n",
    "                                                100*(1-alpha_ci/2)])\n",
    "        t_stats  = None\n",
    "\n",
    "    else:\n",
    "        # studentized-t CIs\n",
    "        #cov_orig      = np.linalg.inv(H_orig)\n",
    "        try:\n",
    "            cov_orig = np.linalg.inv(H_reg)\n",
    "        except np.linalg.LinAlgError:\n",
    "            cov_orig = np.linalg.pinv(H_reg)\n",
    "\n",
    "        with np.errstate(invalid=\"ignore\"):\n",
    "            se_orig    = np.sqrt(np.diag(cov_orig) / T)\n",
    "        t_stats, _    = _compute_studentized_t(boot_est, boot_hess,\n",
    "                                               theta_hat, events, T)\n",
    "        ci_low, ci_up = _symmetrized_ci(theta_hat, t_stats, se_orig, alpha_ci)\n",
    "\n",
    "        # studentized-t for alpha = η·β\n",
    "        grad0       = np.array([0.0, beta_h, eta_h])\n",
    "        var0_alpha  = max(grad0 @ cov_orig @ grad0, 0.0)\n",
    "        se0_alpha   = np.sqrt(var0_alpha / T)\n",
    "        ci_alpha    = _studentized_alpha_ci(theta_hat, boot_est, boot_hess,\n",
    "                                            se0_alpha, alpha_ci, T)\n",
    "\n",
    "    # 6) Coverage & return\n",
    "    coverage       = ((true_params >= ci_low) & (true_params <= ci_up)).astype(int)\n",
    "    alpha0         = true_params[1] * true_params[2]\n",
    "    coverage_alpha = int(ci_alpha[0] <= alpha0 <= ci_alpha[1])\n",
    "    boot_lr_reject = int(np.mean(np.array(LR_star) >= LR_obs) < alpha_ci)\n",
    "\n",
    "    return {\n",
    "        'theta_hat':         theta_hat,\n",
    "        'ci_lower':          ci_low,\n",
    "        'ci_upper':          ci_up,\n",
    "        'ci_alpha':          ci_alpha,\n",
    "        't_stats':           t_stats,\n",
    "        'coverage':          coverage,\n",
    "        'coverage_alpha':    coverage_alpha,\n",
    "        'boot_lr_reject':    boot_lr_reject,\n",
    "        'stationarity_fail':  stationarity_fail,\n",
    "        'hessian_fail':       hessian_fail\n",
    "    }\n",
    "\n",
    "\n",
    "def np_fixed_intensity_bootstrap(events, T, B, true_params, alpha_ci=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    Nonparametric Fixed-Intensity Bootstrap (NP-FIB) with\n",
    "    symmetrized-t CIs and percentile fallback on Hessian failure.\n",
    "    \"\"\"\n",
    "    ### Follows the same structure as previous functions with the difference being the rescaling in step 4 ###\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # 1) Fit original MLE\n",
    "    theta_hat = fit_hawkes_MLE(events, T)\n",
    "    mu_h, eta_h, beta_h = theta_hat\n",
    "\n",
    "    # 2) Stationarity & Hessian checks\n",
    "\n",
    "    stationarity_fail = (eta_h >= 1)\n",
    "    H_orig = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T)\n",
    "\n",
    "    # robust PD test\n",
    "    H_sym = 0.5 * (H_orig + H_orig.T)\n",
    "    H_reg = H_sym + 1e-8 * np.eye(H_sym.shape[0])\n",
    "    try:\n",
    "        eigs = np.linalg.eigvalsh(H_reg)\n",
    "        hessian_fail = np.any(eigs <= 0)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fallback to Cholesky\n",
    "        try:\n",
    "            np.linalg.cholesky(H_reg)\n",
    "            hessian_fail = False\n",
    "        except np.linalg.LinAlgError:\n",
    "            hessian_fail = True\n",
    "\n",
    "    # 3) Observed LR statistic\n",
    "    ll_hat, ll_0 = ell_T(events, theta_hat, T), ell_T(events, true_params, T)\n",
    "    LR_obs       = 2 * (ll_hat - ll_0)\n",
    "\n",
    "    # 4) Rescale residuals usinf the helper function\n",
    "    v_c      = compute_rescaled_residuals(events, T, theta_hat)\n",
    "    s_max    = Lambda(T, events, theta_hat) # fixing the intensity\n",
    "\n",
    "    # 5) Draw B bootstrap samples\n",
    "    boot_est = []\n",
    "    LR_star  = []\n",
    "    boot_hess = []\n",
    "    for _ in range(B):\n",
    "        v_star = np.random.choice(v_c, size=len(v_c), replace=True)\n",
    "        s_cum  = np.cumsum(v_star)\n",
    "        t_star = [Lambda_inv(s, events, theta_hat, T)\n",
    "                  for s in s_cum if s <= s_max]\n",
    "\n",
    "        th_b = fit_hawkes_MLE(t_star, T)\n",
    "        boot_est.append(th_b)\n",
    "        LR_star.append(2 * (ell_T(t_star, th_b, T)\n",
    "                             - ell_T(t_star, theta_hat, T)))\n",
    "        H_B = compute_finite_diff_hessian(hawkes_loglik, th_b, t_star, T)\n",
    "        boot_hess.append(H_B)\n",
    "\n",
    "    boot_est   = np.vstack(boot_est)\n",
    "    alpha_boot = boot_est[:,1] * boot_est[:,2]\n",
    "\n",
    "    # 6) Build CIs\n",
    "    if hessian_fail:\n",
    "        # ------ Percentile fallback ------\n",
    "        ci_low   = np.percentile(boot_est,   100*(alpha_ci/2),    axis=0)\n",
    "        ci_up    = np.percentile(boot_est,   100*(1-alpha_ci/2),  axis=0)\n",
    "        ci_alpha = np.percentile(alpha_boot, [100*(alpha_ci/2),\n",
    "                                              100*(1-alpha_ci/2)])\n",
    "        t_stats  = None\n",
    "\n",
    "    else:\n",
    "        # ------ Studentized-t CI ------\n",
    "        #cov_orig      = np.linalg.inv(H_orig)\n",
    "\n",
    "        try:\n",
    "            cov_orig = np.linalg.inv(H_reg)\n",
    "        except np.linalg.LinAlgError:\n",
    "            cov_orig = np.linalg.pinv(H_reg)\n",
    "\n",
    "\n",
    "        with np.errstate(invalid=\"ignore\"):\n",
    "            se_orig    = np.sqrt(np.diag(cov_orig) / T)\n",
    "\n",
    "        # need to recompute boot_hess to feed into _compute_studentized_t\n",
    "        t_stats, _    = _compute_studentized_t(boot_est, boot_hess,\n",
    "                                               theta_hat, events, T)\n",
    "        ci_low, ci_up = _symmetrized_ci(theta_hat, t_stats, se_orig, alpha_ci)\n",
    "\n",
    "        # studentized-t for alpha\n",
    "        grad0       = np.array([0.0, beta_h, eta_h])\n",
    "        var0_alpha  = max(grad0 @ cov_orig @ grad0, 0.0)\n",
    "        se0_alpha   = np.sqrt(var0_alpha / T)\n",
    "        ci_alpha    = _studentized_alpha_ci(theta_hat, boot_est, boot_hess,\n",
    "                                            se0_alpha, alpha_ci, T)\n",
    "\n",
    "    # 7) Coverage & return\n",
    "    coverage       = ((true_params >= ci_low) & (true_params <= ci_up)).astype(int)\n",
    "    alpha0         = true_params[1] * true_params[2]\n",
    "    coverage_alpha = int(ci_alpha[0] <= alpha0 <= ci_alpha[1])\n",
    "    boot_lr_reject = int(np.mean(np.array(LR_star) >= LR_obs) < alpha_ci)\n",
    "\n",
    "    return {\n",
    "        'theta_hat':         theta_hat,\n",
    "        'ci_lower':          ci_low,\n",
    "        'ci_upper':          ci_up,\n",
    "        'ci_alpha':          ci_alpha,\n",
    "        't_stats':           t_stats,\n",
    "        'coverage':          coverage,\n",
    "        'coverage_alpha':    coverage_alpha,\n",
    "        'boot_lr_reject':    boot_lr_reject,\n",
    "        'stationarity_fail':  stationarity_fail,\n",
    "        'hessian_fail':       hessian_fail\n",
    "    }\n",
    "\n",
    "\n",
    "def np_recursive_intensity_bootstrap(events, T, B, true_params, alpha_ci=0.05, seed=None):\n",
    "    \"\"\"\n",
    "    Nonparametric Recursive-Intensity Bootstrap (NP-RIB) with\n",
    "    symmetrized-t CIs and percentile fallback on Hessian failure.\n",
    "    \"\"\"\n",
    "    ### Follows the same structure as previous function without fixing the intensity in step 4 but computing it for each sample ###\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # 1) Fit original MLE\n",
    "    theta_hat = fit_hawkes_MLE(events, T)\n",
    "    mu_h, eta_h, beta_h = theta_hat\n",
    "\n",
    "    # 2) Stationarity & Hessian checks\n",
    "\n",
    "    stationarity_fail = (eta_h >= 1)\n",
    "    H_orig = compute_finite_diff_hessian(hawkes_loglik, theta_hat, events, T)\n",
    "\n",
    "    # robust PD test\n",
    "    H_sym = 0.5 * (H_orig + H_orig.T)\n",
    "    H_reg = H_sym + 1e-8 * np.eye(H_sym.shape[0])\n",
    "    try:\n",
    "        eigs = np.linalg.eigvalsh(H_reg)\n",
    "        hessian_fail = np.any(eigs <= 0)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # fallback to Cholesky\n",
    "        try:\n",
    "            np.linalg.cholesky(H_reg)\n",
    "            hessian_fail = False\n",
    "        except np.linalg.LinAlgError:\n",
    "            hessian_fail = True\n",
    "\n",
    "\n",
    "    # 3) Observed LR statistic\n",
    "    ll_hat, ll_0 = ell_T(events, theta_hat, T), ell_T(events, true_params, T)\n",
    "    LR_obs       = 2 * (ll_hat - ll_0)\n",
    "\n",
    "    # 4) Rescale residuals\n",
    "    v_c      = compute_rescaled_residuals(events, T, theta_hat)\n",
    "    s_max    = mu_h * T\n",
    "\n",
    "    # 5) Draw B bootstrap samples\n",
    "    boot_est    = []\n",
    "    alpha_boot  = []\n",
    "    LR_star     = []\n",
    "    boot_hess   = []\n",
    "    for _ in range(B):\n",
    "        v_star = np.random.choice(v_c, size=len(v_c), replace=True)\n",
    "        cum, t_star = 0.0, []\n",
    "        for v in v_star:\n",
    "            if cum + v > s_max:\n",
    "                break\n",
    "            cum += v\n",
    "            t_star.append(Lambda_inv(cum, t_star, theta_hat, T))\n",
    "\n",
    "        th_b = fit_hawkes_MLE(t_star, T)\n",
    "        boot_est.append(th_b)\n",
    "        alpha_boot.append(th_b[1] * th_b[2])\n",
    "        LR_star.append(2 * (ell_T(t_star, th_b, T)\n",
    "                             - ell_T(t_star, theta_hat, T)))\n",
    "        H_B = compute_finite_diff_hessian(hawkes_loglik, th_b, t_star, T)\n",
    "        boot_hess.append(H_B)\n",
    "\n",
    "    boot_est    = np.vstack(boot_est)\n",
    "    alpha_boot  = np.array(alpha_boot)\n",
    "\n",
    "    # 6) CI construction\n",
    "    if hessian_fail:\n",
    "        # ------ Percentile fallback ------\n",
    "        ci_low   = np.percentile(boot_est,   100*(alpha_ci/2),    axis=0)\n",
    "        ci_up    = np.percentile(boot_est,   100*(1-alpha_ci/2),  axis=0)\n",
    "        ci_alpha = np.percentile(alpha_boot, [100*(alpha_ci/2),\n",
    "                                              100*(1-alpha_ci/2)])\n",
    "        t_stats  = None\n",
    "\n",
    "    else:\n",
    "        # ------ Studentized-t CI ------\n",
    "        #cov_orig      = np.linalg.inv(H_orig)\n",
    "\n",
    "        try:\n",
    "            cov_orig = np.linalg.inv(H_reg)\n",
    "        except np.linalg.LinAlgError:\n",
    "            cov_orig = np.linalg.pinv(H_reg)\n",
    "\n",
    "\n",
    "\n",
    "        with np.errstate(invalid=\"ignore\"):\n",
    "            se_orig    = np.sqrt(np.diag(cov_orig) / T)\n",
    "\n",
    "        t_stats, _    = _compute_studentized_t(boot_est, boot_hess,\n",
    "                                               theta_hat, events, T)\n",
    "        ci_low, ci_up = _symmetrized_ci(theta_hat, t_stats, se_orig, alpha_ci)\n",
    "\n",
    "        # studentized-t for alpha \n",
    "        grad0       = np.array([0.0, beta_h, eta_h])\n",
    "        var0_alpha  = max(grad0 @ cov_orig @ grad0, 0.0)\n",
    "        se0_alpha   = np.sqrt(var0_alpha / T)\n",
    "        ci_alpha    = _studentized_alpha_ci(theta_hat, boot_est, boot_hess,\n",
    "                                            se0_alpha, alpha_ci, T)\n",
    "\n",
    "    # 7) Coverage & return\n",
    "    coverage       = ((true_params >= ci_low) & (true_params <= ci_up)).astype(int)\n",
    "    alpha0         = true_params[1] * true_params[2]\n",
    "    coverage_alpha = int(ci_alpha[0] <= alpha0 <= ci_alpha[1])\n",
    "    boot_lr_reject = int(np.mean(np.array(LR_star) >= LR_obs) < alpha_ci)\n",
    "\n",
    "    return {\n",
    "        'theta_hat':         theta_hat,\n",
    "        'ci_lower':          ci_low,\n",
    "        'ci_upper':          ci_up,\n",
    "        'ci_alpha':          ci_alpha,\n",
    "        't_stats':           t_stats,\n",
    "        'coverage':          coverage,\n",
    "        'coverage_alpha':    coverage_alpha,\n",
    "        'boot_lr_reject':    boot_lr_reject,\n",
    "        'stationarity_fail':  stationarity_fail,\n",
    "        'hessian_fail':       hessian_fail\n",
    "    }\n",
    "\n",
    "def monte_carlo_coverage_compare(\n",
    "    mu, alpha, beta,\n",
    "    T, M, k,\n",
    "    B=50, R=20,\n",
    "    alpha_ci=0.05,\n",
    "    seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run R Monte Carlo replications, each with B bootstraps,\n",
    "    and report estimated coverage for (μ,η,β,α) under:\n",
    "      • Asymptotic\n",
    "      • FIB, RIB, NP-FIB, NP-RIB\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    theta0 = np.array([mu, alpha/beta, beta])\n",
    "\n",
    "    # 1) Define a little adapter for the asymptotic method so it matches the bootstrap interface\n",
    "    def asym_wrapper(events, T, B, theta0, alpha_ci, seed=None):\n",
    "        out = asymptotic_inference(events, T, theta0, alpha=alpha_ci)\n",
    "        return {\n",
    "            'coverage':       out['coverage'],        # array [covμ,covη,covβ]\n",
    "            'coverage_alpha': out['coverage_alpha'],  # 0/1\n",
    "            'boot_lr_reject': out['LR_reject'],       # 0/1\n",
    "        }\n",
    "\n",
    "    # 2) putting all methods in a single dict\n",
    "    methods = {\n",
    "        'Asymptotic':            asym_wrapper,\n",
    "        'FIB':                   fixed_intensity_bootstrap,\n",
    "        'RIB':                   recursive_intensity_bootstrap,\n",
    "        'NP-FIB':                np_fixed_intensity_bootstrap,\n",
    "        'NP-RIB':                np_recursive_intensity_bootstrap,\n",
    "    }\n",
    "\n",
    "    # 3) Prepare counters\n",
    "    hits    = {name: np.zeros(4, dtype=int) for name in methods}\n",
    "    rejects = {name: 0 for name in methods}\n",
    "\n",
    "    # 4) Monte Carlo loop\n",
    "    for r in range(R):\n",
    "        events = simulate_hawkes(mu, alpha, beta, T, M, k)\n",
    "        for name, fn in methods.items():\n",
    "            res = fn(events, T, B, theta0, alpha_ci, seed and seed + r)\n",
    "            # accumulate coverage for μ,η,β\n",
    "            hits[name][:3] += res['coverage']\n",
    "            # accumulate coverage for α=ηβ\n",
    "            hits[name][3]  += res['coverage_alpha']\n",
    "            # accumulate LR rejection\n",
    "            rejects[name]  += int(res['boot_lr_reject'])\n",
    "            \n",
    "\n",
    "    # 5) Build summary\n",
    "    summary = {}\n",
    "    for name in methods:\n",
    "        summary[name] = {\n",
    "            'cov(μ,η,β)': np.round(hits[name][:3] / R, 4),\n",
    "            'cov(α)':      round(hits[name][3]    / R,    4),\n",
    "            'rejLR':       round(rejects[name]    / R,    4),\n",
    "        }\n",
    "    return summary\n",
    "\n",
    "def timed_monte_carlo(*args, **kwargs):\n",
    "    t0 = time.perf_counter()\n",
    "    out = monte_carlo_coverage_compare(*args, **kwargs)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    print(f\"Total MC + bootstraps elapsed: {elapsed:.1f} s\")\n",
    "    return out\n",
    "\n",
    "def monte_carlo_sanity_failures(\n",
    "    configs,         # list of (mu, alpha, beta) triples\n",
    "    T, M, k,         # Hawkes simulation params\n",
    "    R=20,           # Monte Carlo reps per config\n",
    "    seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For each (mu,alpha,beta) in `configs`, estimate by simulation:\n",
    "      • P(stationarity_fail) under the asymptotic fit\n",
    "      • P(hessian_fail)      under the asymptotic fit\n",
    "\n",
    "    Returns a dict mapping config->(p_stationarity_fail, p_hessian_fail).\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    results = {}\n",
    "    for (mu, alpha, beta) in configs:\n",
    "        theta0 = np.array([mu, alpha / beta, beta])\n",
    "        stat_count = 0\n",
    "        hess_count = 0\n",
    "\n",
    "        for r in range(R):\n",
    "            # 1) simulate one path\n",
    "            events = simulate_hawkes(mu, alpha, beta, T, M, k)\n",
    "\n",
    "            # 2) fit + diag via your asymptotic_inference\n",
    "            out = asymptotic_inference(events, T, theta0)\n",
    "\n",
    "            # 3) tally failures\n",
    "            stat_count += int(out['stationarity_fail'])\n",
    "            hess_count += int(out['hessian_fail'])\n",
    "\n",
    "        results[(mu, alpha, beta)] = (\n",
    "            stat_count / R,\n",
    "            hess_count / R\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def monte_carlo_sanity_failures(configs, T, M_func, k, R=100, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    results = {}\n",
    "    for mu, alpha, beta in configs:\n",
    "        theta0 = np.array([mu, alpha/beta, beta])\n",
    "        stat_count = 0\n",
    "        hess_count = 0\n",
    "        for _ in range(R):\n",
    "            events = simulate_hawkes(mu, alpha, beta, T, M_func(mu, alpha, beta), k)\n",
    "            out = asymptotic_inference(events, T, theta0)\n",
    "            stat_count += int(out['stationarity_fail'])\n",
    "            hess_count += int(out['hessian_fail'])\n",
    "        results[(mu, alpha, beta)] = (stat_count / R, hess_count / R)\n",
    "    return results\n",
    "\n",
    "\n",
    "def M_func(mu, alpha, beta):\n",
    "    # We choose C=3 \n",
    "    return mu+alpha**(1.2) * beta**(-0.1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed8b076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_06a2e_row0_col0, #T_06a2e_row1_col0, #T_06a2e_row2_col0, #T_06a2e_row3_col0, #T_06a2e_row4_col0, #T_06a2e_row5_col0, #T_06a2e_row6_col0, #T_06a2e_row7_col0 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_06a2e_row0_col1 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_06a2e_row1_col1 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_06a2e_row2_col1, #T_06a2e_row5_col1 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_06a2e_row3_col1 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_06a2e_row4_col1 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_06a2e_row6_col1, #T_06a2e_row7_col1 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_06a2e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_06a2e_level0_col0\" class=\"col_heading level0 col0\" >P(stat_fail)</th>\n",
       "      <th id=\"T_06a2e_level0_col1\" class=\"col_heading level0 col1\" >P(hess_fail)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Config</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row0\" class=\"row_heading level0 row0\" >μ=0.2, α=0.5, β=1.0</th>\n",
       "      <td id=\"T_06a2e_row0_col0\" class=\"data row0 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row0_col1\" class=\"data row0 col1\" >0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row1\" class=\"row_heading level0 row1\" >μ=0.2, α=0.5, β=25.0</th>\n",
       "      <td id=\"T_06a2e_row1_col0\" class=\"data row1 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row1_col1\" class=\"data row1 col1\" >0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row2\" class=\"row_heading level0 row2\" >μ=0.2, α=0.8, β=1.0</th>\n",
       "      <td id=\"T_06a2e_row2_col0\" class=\"data row2 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row2_col1\" class=\"data row2 col1\" >0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row3\" class=\"row_heading level0 row3\" >μ=0.2, α=0.8, β=25.0</th>\n",
       "      <td id=\"T_06a2e_row3_col0\" class=\"data row3 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row3_col1\" class=\"data row3 col1\" >0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row4\" class=\"row_heading level0 row4\" >μ=0.8, α=0.5, β=1.0</th>\n",
       "      <td id=\"T_06a2e_row4_col0\" class=\"data row4 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row4_col1\" class=\"data row4 col1\" >0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row5\" class=\"row_heading level0 row5\" >μ=0.8, α=0.5, β=25.0</th>\n",
       "      <td id=\"T_06a2e_row5_col0\" class=\"data row5 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row5_col1\" class=\"data row5 col1\" >0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row6\" class=\"row_heading level0 row6\" >μ=0.8, α=0.8, β=1.0</th>\n",
       "      <td id=\"T_06a2e_row6_col0\" class=\"data row6 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row6_col1\" class=\"data row6 col1\" >0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_06a2e_level0_row7\" class=\"row_heading level0 row7\" >μ=0.8, α=0.8, β=25.0</th>\n",
       "      <td id=\"T_06a2e_row7_col0\" class=\"data row7 col0\" >0.00</td>\n",
       "      <td id=\"T_06a2e_row7_col1\" class=\"data row7 col1\" >0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1409cf020>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Sanity check ###\n",
    "# Set the parameter cofiguration for sanity checks\n",
    "configs = [\n",
    "    (0.2, 0.5, 1.0),\n",
    "    (0.2, 0.5, 25.0),\n",
    "    (0.2, 0.8, 1.0),\n",
    "    (0.2, 0.8, 25.0),\n",
    "    (0.8, 0.5, 1.0),\n",
    "    (0.8, 0.5, 25.0),\n",
    "    (0.8, 0.8, 1.0),\n",
    "    (0.8, 0.8, 25.0),\n",
    "]\n",
    "\n",
    "T = 50 # simulation time can be adjusted\n",
    "k = 100\n",
    "R = 20\n",
    "seed = 123\n",
    "\n",
    "\n",
    "# Compute results\n",
    "results = monte_carlo_sanity_failures(configs, T, M_func, k, R=R, seed=seed)\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame([\n",
    "    {'Config': f\"μ={mu}, α={alpha}, β={beta}\",\n",
    "     'P(stat_fail)': p_stat,\n",
    "     'P(hess_fail)': p_hess}\n",
    "    for (mu, alpha, beta), (p_stat, p_hess) in results.items()\n",
    "])\n",
    "\n",
    "df = df.set_index('Config')\n",
    "\n",
    "# Display styled\n",
    "styled = df.style.background_gradient(cmap='coolwarm', vmin=0, vmax=1).format(\"{:.2f}\")\n",
    "display(styled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11305f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Running MC for μ=0.2, α=0.5, β=1.0, T=50\n",
      "  done in 88.8s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.5, β=1.0, T=100\n",
      "  done in 256.2s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.5, β=25, T=50\n",
      "  done in 45.5s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.5, β=25, T=100\n",
      "  done in 118.3s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.8, β=1.0, T=50\n",
      "  done in 180.5s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.8, β=1.0, T=100\n",
      "  done in 595.6s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.8, β=25, T=50\n",
      "  done in 46.9s\n",
      "\n",
      "→ Running MC for μ=0.2, α=0.8, β=25, T=100\n",
      "  done in 123.9s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.5, β=1.0, T=50\n",
      "  done in 818.7s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.5, β=1.0, T=100\n",
      "  done in 3473.9s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.5, β=25, T=50\n",
      "  done in 435.1s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.5, β=25, T=100\n",
      "  done in 1720.1s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.8, β=1.0, T=50\n",
      "  done in 1253.8s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.8, β=1.0, T=100\n",
      "  done in 5553.4s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.8, β=25, T=50\n",
      "  done in 433.8s\n",
      "\n",
      "→ Running MC for μ=0.8, α=0.8, β=25, T=100\n",
      "  done in 1697.3s\n",
      "\n",
      "Config μ=0.2, α=0.5, β=1.0, T=50\n",
      "  Asymptotic: covμ=0.75, covη=0.65, covβ=0.75, covα=0.75, rejLR=0.05\n",
      "  FIB     : covμ=0.90, covη=0.60, covβ=1.00, covα=1.00, rejLR=0.10\n",
      "  RIB     : covμ=0.75, covη=0.65, covβ=1.00, covα=1.00, rejLR=0.10\n",
      "  NP-FIB  : covμ=0.80, covη=0.65, covβ=1.00, covα=0.85, rejLR=0.25\n",
      "  NP-RIB  : covμ=0.75, covη=0.60, covβ=0.95, covα=0.90, rejLR=0.25\n",
      "\n",
      "Config μ=0.2, α=0.5, β=1.0, T=100\n",
      "  Asymptotic: covμ=0.55, covη=0.50, covβ=0.60, covα=0.75, rejLR=0.10\n",
      "  FIB     : covμ=0.95, covη=0.90, covβ=0.95, covα=0.95, rejLR=0.10\n",
      "  RIB     : covμ=0.60, covη=1.00, covβ=1.00, covα=0.95, rejLR=0.05\n",
      "  NP-FIB  : covμ=0.95, covη=1.00, covβ=0.95, covα=0.85, rejLR=0.10\n",
      "  NP-RIB  : covμ=0.60, covη=1.00, covβ=0.90, covα=0.85, rejLR=0.05\n",
      "\n",
      "Config μ=0.2, α=0.5, β=25, T=50\n",
      "  Asymptotic: covμ=0.10, covη=0.10, covβ=0.10, covα=0.10, rejLR=0.05\n",
      "  FIB     : covμ=0.55, covη=0.50, covβ=0.15, covα=0.55, rejLR=0.20\n",
      "  RIB     : covμ=0.35, covη=0.60, covβ=0.20, covα=0.55, rejLR=0.20\n",
      "  NP-FIB  : covμ=0.10, covη=0.45, covβ=0.10, covα=0.15, rejLR=0.45\n",
      "  NP-RIB  : covμ=0.15, covη=0.45, covβ=0.15, covα=0.20, rejLR=0.30\n",
      "\n",
      "Config μ=0.2, α=0.5, β=25, T=100\n",
      "  Asymptotic: covμ=0.25, covη=0.25, covβ=0.15, covα=0.25, rejLR=0.00\n",
      "  FIB     : covμ=0.60, covη=0.75, covβ=0.20, covα=0.75, rejLR=0.00\n",
      "  RIB     : covμ=0.50, covη=0.80, covβ=0.20, covα=0.75, rejLR=0.05\n",
      "  NP-FIB  : covμ=0.35, covη=0.70, covβ=0.30, covα=0.45, rejLR=0.15\n",
      "  NP-RIB  : covμ=0.30, covη=0.75, covβ=0.30, covα=0.40, rejLR=0.10\n",
      "\n",
      "Config μ=0.2, α=0.8, β=1.0, T=50\n",
      "  Asymptotic: covμ=0.80, covη=0.80, covβ=0.80, covα=0.80, rejLR=0.05\n",
      "  FIB     : covμ=0.80, covη=0.85, covβ=0.95, covα=0.95, rejLR=0.05\n",
      "  RIB     : covμ=0.95, covη=0.80, covβ=0.95, covα=0.75, rejLR=0.00\n",
      "  NP-FIB  : covμ=0.80, covη=0.75, covβ=0.95, covα=0.85, rejLR=0.10\n",
      "  NP-RIB  : covμ=0.95, covη=0.75, covβ=0.95, covα=0.70, rejLR=0.10\n",
      "\n",
      "Config μ=0.2, α=0.8, β=1.0, T=100\n",
      "  Asymptotic: covμ=0.90, covη=0.80, covβ=0.90, covα=0.90, rejLR=0.20\n",
      "  FIB     : covμ=0.90, covη=0.85, covβ=0.95, covα=0.95, rejLR=0.10\n",
      "  RIB     : covμ=0.95, covη=0.80, covβ=0.95, covα=0.65, rejLR=0.10\n",
      "  NP-FIB  : covμ=0.90, covη=0.85, covβ=0.95, covα=0.80, rejLR=0.20\n",
      "  NP-RIB  : covμ=0.95, covη=0.80, covβ=0.90, covα=0.65, rejLR=0.10\n",
      "\n",
      "Config μ=0.2, α=0.8, β=25, T=50\n",
      "  Asymptotic: covμ=0.40, covη=0.35, covβ=0.20, covα=0.40, rejLR=0.00\n",
      "  FIB     : covμ=0.70, covη=0.75, covβ=0.45, covα=0.70, rejLR=0.00\n",
      "  RIB     : covμ=0.55, covη=0.80, covβ=0.35, covα=0.70, rejLR=0.00\n",
      "  NP-FIB  : covμ=0.50, covη=0.60, covβ=0.45, covα=0.50, rejLR=0.20\n",
      "  NP-RIB  : covμ=0.50, covη=0.70, covβ=0.40, covα=0.55, rejLR=0.20\n",
      "\n",
      "Config μ=0.2, α=0.8, β=25, T=100\n",
      "  Asymptotic: covμ=0.30, covη=0.30, covβ=0.20, covα=0.30, rejLR=0.10\n",
      "  FIB     : covμ=0.70, covη=0.70, covβ=0.30, covα=0.65, rejLR=0.05\n",
      "  RIB     : covμ=0.65, covη=0.80, covβ=0.30, covα=0.70, rejLR=0.05\n",
      "  NP-FIB  : covμ=0.45, covη=0.60, covβ=0.35, covα=0.35, rejLR=0.15\n",
      "  NP-RIB  : covμ=0.40, covη=0.55, covβ=0.35, covα=0.45, rejLR=0.20\n",
      "\n",
      "Config μ=0.8, α=0.5, β=1.0, T=50\n",
      "  Asymptotic: covμ=0.50, covη=0.50, covβ=0.50, covα=0.50, rejLR=0.40\n",
      "  FIB     : covμ=0.60, covη=0.40, covβ=0.55, covα=0.40, rejLR=0.60\n",
      "  RIB     : covμ=0.55, covη=0.50, covβ=0.50, covα=0.35, rejLR=0.40\n",
      "  NP-FIB  : covμ=0.60, covη=0.50, covβ=0.55, covα=0.45, rejLR=0.40\n",
      "  NP-RIB  : covμ=0.55, covη=0.50, covβ=0.55, covα=0.35, rejLR=0.20\n",
      "\n",
      "Config μ=0.8, α=0.5, β=1.0, T=100\n",
      "  Asymptotic: covμ=0.55, covη=0.40, covβ=0.55, covα=0.50, rejLR=0.70\n",
      "  FIB     : covμ=0.65, covη=0.35, covβ=0.60, covα=0.60, rejLR=0.65\n",
      "  RIB     : covμ=0.80, covη=0.70, covβ=0.60, covα=0.50, rejLR=0.35\n",
      "  NP-FIB  : covμ=0.65, covη=0.65, covβ=0.50, covα=0.35, rejLR=0.30\n",
      "  NP-RIB  : covμ=0.75, covη=0.70, covβ=0.40, covα=0.30, rejLR=0.15\n",
      "\n",
      "Config μ=0.8, α=0.5, β=25, T=50\n",
      "  Asymptotic: covμ=0.30, covη=0.30, covβ=0.05, covα=0.35, rejLR=0.00\n",
      "  FIB     : covμ=0.45, covη=0.40, covβ=0.35, covα=0.40, rejLR=0.05\n",
      "  RIB     : covμ=0.45, covη=0.50, covβ=0.30, covα=0.40, rejLR=0.05\n",
      "  NP-FIB  : covμ=0.40, covη=0.40, covβ=0.25, covα=0.30, rejLR=0.05\n",
      "  NP-RIB  : covμ=0.40, covη=0.45, covβ=0.25, covα=0.30, rejLR=0.05\n",
      "\n",
      "Config μ=0.8, α=0.5, β=25, T=100\n",
      "  Asymptotic: covμ=0.15, covη=0.15, covβ=0.00, covα=0.10, rejLR=0.15\n",
      "  FIB     : covμ=0.55, covη=0.55, covβ=0.25, covα=0.40, rejLR=0.15\n",
      "  RIB     : covμ=0.35, covη=0.40, covβ=0.25, covα=0.25, rejLR=0.15\n",
      "  NP-FIB  : covμ=0.45, covη=0.45, covβ=0.25, covα=0.25, rejLR=0.10\n",
      "  NP-RIB  : covμ=0.35, covη=0.30, covβ=0.20, covα=0.30, rejLR=0.10\n",
      "\n",
      "Config μ=0.8, α=0.8, β=1.0, T=50\n",
      "  Asymptotic: covμ=0.60, covη=0.25, covβ=0.60, covα=0.55, rejLR=1.00\n",
      "  FIB     : covμ=0.45, covη=0.20, covβ=0.75, covα=0.55, rejLR=0.90\n",
      "  RIB     : covμ=0.60, covη=0.35, covβ=0.70, covα=0.45, rejLR=0.60\n",
      "  NP-FIB  : covμ=0.50, covη=0.20, covβ=0.60, covα=0.45, rejLR=0.85\n",
      "  NP-RIB  : covμ=0.60, covη=0.30, covβ=0.60, covα=0.30, rejLR=0.65\n",
      "\n",
      "Config μ=0.8, α=0.8, β=1.0, T=100\n",
      "  Asymptotic: covμ=0.55, covη=0.00, covβ=0.75, covα=0.45, rejLR=1.00\n",
      "  FIB     : covμ=0.45, covη=0.00, covβ=0.80, covα=0.45, rejLR=1.00\n",
      "  RIB     : covμ=0.75, covη=0.50, covβ=0.70, covα=0.25, rejLR=0.55\n",
      "  NP-FIB  : covμ=0.35, covη=0.50, covβ=0.65, covα=0.25, rejLR=0.95\n",
      "  NP-RIB  : covμ=0.80, covη=0.50, covβ=0.65, covα=0.10, rejLR=0.55\n",
      "\n",
      "Config μ=0.8, α=0.8, β=25, T=50\n",
      "  Asymptotic: covμ=0.15, covη=0.15, covβ=0.00, covα=0.00, rejLR=0.00\n",
      "  FIB     : covμ=0.40, covη=0.45, covβ=0.00, covα=0.30, rejLR=0.10\n",
      "  RIB     : covμ=0.25, covη=0.45, covβ=0.05, covα=0.25, rejLR=0.00\n",
      "  NP-FIB  : covμ=0.25, covη=0.45, covβ=0.00, covα=0.05, rejLR=0.05\n",
      "  NP-RIB  : covμ=0.25, covη=0.40, covβ=0.00, covα=0.10, rejLR=0.00\n",
      "\n",
      "Config μ=0.8, α=0.8, β=25, T=100\n",
      "  Asymptotic: covμ=0.15, covη=0.10, covβ=0.15, covα=0.10, rejLR=0.00\n",
      "  FIB     : covμ=0.65, covη=0.65, covβ=0.30, covα=0.25, rejLR=0.05\n",
      "  RIB     : covμ=0.30, covη=0.40, covβ=0.30, covα=0.25, rejLR=0.00\n",
      "  NP-FIB  : covμ=0.45, covη=0.50, covβ=0.20, covα=0.20, rejLR=0.00\n",
      "  NP-RIB  : covμ=0.35, covη=0.50, covβ=0.15, covα=0.20, rejLR=0.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compare_grid_over_T(\n",
    "    mus, alphas, betas, Ts,\n",
    "    M_func,        # a function M(mu,alpha,beta) to compute M if needed\n",
    "    k,\n",
    "    B=199, R=20,\n",
    "    alpha_ci=0.05,\n",
    "    seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    For each combination of mu in `mus`, alpha in `alphas`, beta in `betas`, and T in `Ts`,\n",
    "    runs the MC compare and returns a dict:\n",
    "      results[(mu,alpha,beta,T)] = summary_dict\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    for mu in mus:\n",
    "        for alpha in alphas:\n",
    "            for beta in betas:\n",
    "                # compute M (thinning envelope) as a function of parameters\n",
    "                M = M_func(mu, alpha, beta)\n",
    "                for T in Ts:\n",
    "                    theta0 = np.array([mu, alpha/beta, beta])\n",
    "                    print(f\"\\n→ Running MC for μ={mu}, α={alpha}, β={beta}, T={T}\")\n",
    "                    t0 = time.perf_counter()\n",
    "                    summary = monte_carlo_coverage_compare(\n",
    "                        mu, alpha, beta,\n",
    "                        T, M, k,\n",
    "                        B=B, R=R,\n",
    "                        alpha_ci=alpha_ci,\n",
    "                        seed=seed\n",
    "                    )\n",
    "                    elapsed = time.perf_counter() - t0\n",
    "                    print(f\"  done in {elapsed:.1f}s\")\n",
    "                    all_results[(mu, alpha, beta, T)] = summary\n",
    "    return all_results\n",
    "\n",
    "# Example of a simple M_func:\n",
    "\n",
    "# Define your grids\n",
    "mus    = [0.2, 0.8]\n",
    "alphas = [0.5, 0.8]\n",
    "betas  = [1.0, 25]\n",
    "Ts     = [50, 100]\n",
    "\n",
    "# Run the sweep\n",
    "results = compare_grid_over_T(\n",
    "    mus, alphas, betas, Ts,\n",
    "    M_func=M_func,\n",
    "    k=100,\n",
    "    B=199, R=20,\n",
    "    alpha_ci=0.05,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Print neatly\n",
    "for (mu, alpha, beta, T), summary in results.items():\n",
    "    print(f\"\\nConfig μ={mu}, α={alpha}, β={beta}, T={T}\")\n",
    "    for method, stats in summary.items():\n",
    "        cov_mu, cov_eta, cov_beta = stats['cov(μ,η,β)']\n",
    "        cov_alpha = stats['cov(α)']\n",
    "        rejLR     = stats['rejLR']\n",
    "        print(f\"  {method:8s}: covμ={cov_mu:.2f}, covη={cov_eta:.2f}, covβ={cov_beta:.2f}, covα={cov_alpha:.2f}, rejLR={rejLR:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lengt of confidence intervals\n",
    "\n",
    "#modifying the simulation function\n",
    "def simulate_hawkes1(mu, alpha, beta, T, M=mu+alpha**(1.2)*beta**(-0.1), k=100.0):\n",
    "    \"\"\"\n",
    "    Simulate Hawkes process via Ogata's thinning algorithm.\n",
    "    \"\"\"\n",
    "    all_events = []\n",
    "    t = -k\n",
    "    while True:\n",
    "        u = np.random.exponential(scale=1.0 / M)\n",
    "        t += u\n",
    "        if t > T:\n",
    "            break\n",
    "        intensity = mu + sum(alpha * np.exp(-beta * (t - ti)) for ti in all_events if t > ti)\n",
    "        if np.random.uniform() <= intensity / M:\n",
    "            all_events.append(t)\n",
    "    \n",
    "    events = [ti for ti in all_events if ti > 0]\n",
    "    return events\n",
    "\n",
    "# Event Generator Wrapper\n",
    "def events_generator(config, T):\n",
    "    mu, eta, beta = config\n",
    "    alpha = eta * beta\n",
    "    return simulate_hawkes1(mu, alpha, beta, T)\n",
    "\n",
    "# CI Length Extraction \n",
    "def get_ci_lengths_all_methods(events, T, config, B=199, alpha=0.05):\n",
    "    mu0, eta0, beta0 = config\n",
    "    true_params = np.array(config)\n",
    "    results = []\n",
    "\n",
    "    methods = [\n",
    "        (\"Asymptotic\", asymptotic_inference(events, T, true_params, alpha)),\n",
    "        (\"FIB\", fixed_intensity_bootstrap(events, T, B, true_params, alpha)),\n",
    "        (\"RIB\", recursive_intensity_bootstrap(events, T, B, true_params, alpha)),\n",
    "        (\"NP-FIB\", np_fixed_intensity_bootstrap(events, T, B, true_params, alpha)),\n",
    "        (\"NP-RIB\", np_recursive_intensity_bootstrap(events, T, B, true_params, alpha)),\n",
    "    ]\n",
    "\n",
    "    for method_name, result in methods:\n",
    "        ci_low = np.array(result[\"ci_lower\"], dtype=float)\n",
    "        ci_up = np.array(result[\"ci_upper\"], dtype=float)\n",
    "        ci_len = ci_up - ci_low\n",
    "        alpha_len = result[\"ci_alpha\"][1] - result[\"ci_alpha\"][0] if not any(np.isnan(result[\"ci_alpha\"])) else np.nan\n",
    "\n",
    "        results.append({\n",
    "            \"method\": method_name,\n",
    "            \"mu\": mu0,\n",
    "            \"eta\": eta0,\n",
    "            \"beta\": beta0,\n",
    "            \"length_mu\": ci_len[0],\n",
    "            \"length_eta\": ci_len[1],\n",
    "            \"length_beta\": ci_len[2],\n",
    "            \"length_alpha\": alpha_len,\n",
    "            \"stationarity_fail\": result.get(\"stationarity_fail\", None),\n",
    "            \"hessian_fail\": result.get(\"hessian_fail\", None)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "#Run All Configs\n",
    "def run_all_configs(events_generator, T, configs, B=199, alpha=0.05):\n",
    "    all_results = []\n",
    "    for config in configs:\n",
    "        events = events_generator(config, T)\n",
    "        method_results = get_ci_lengths_all_methods(events, T, config, B, alpha)\n",
    "        all_results.extend(method_results)\n",
    "    \n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# Configs and Execution\n",
    "configs = [\n",
    "    (0.2, 0.5, 1.0),\n",
    "    (0.2, 0.5, 25.0),\n",
    "    (0.2, 0.8, 1.0),\n",
    "    (0.2, 0.8, 25.0),\n",
    "    (0.8, 0.5, 1.0),\n",
    "    (0.8, 0.5, 25.0),\n",
    "    (0.8, 0.8, 1.0),\n",
    "    (0.8, 0.8, 25.0),\n",
    "]\n",
    "\n",
    "# Run\n",
    "df = run_all_configs(events_generator, T=100, configs=configs, B=199)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
